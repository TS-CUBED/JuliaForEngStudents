[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Julia for Engineering Students",
    "section": "",
    "text": "Preface\nThis is a collection of notes I put together for myself and my students. It may grow into a book some day.\nThis “book” is an incomplete and strongly biased introduction to Julia for students and resesarchers in engineering disciplines. I put it together as a guide for my students and myself and publish it to help colleagues who have shown an interest in using Julia in their own research.\nThis book was created using Quarto, written on Emacs.\nCode is active and the exercises and examples can be downloaded as Jupyter notebooks.\nAll content and examples are published as is and without any guarantee of usefulness or even fitness for purpose1, let alone elegance.1 Although I do think that it will be both useful and is fit for purpose.\n 2023 Torsten Schenkel, CC-BY-4.0"
  },
  {
    "objectID": "intro.html#what-is-julia",
    "href": "intro.html#what-is-julia",
    "title": "1  Introduction",
    "section": "1.1 What is Julia?",
    "text": "1.1 What is Julia?\nJulia is a programming language that is comparable to Matlab and Python, but also has some features of lower level languages like Fortran and C.\nJulia is a dynamically typed, interactive language1, developed and published by researchers at Massachusetts Institute of Technology (MIT)2 and Julia Computing3.1 It is used in a “read-eval-print-loop” (REPL).2 Funny enough that is the same place where Matlab was born.3 For details see Julia Governance.\nJulia is free and open-source software (FOSS), and is available for free for learning, research and commercial use. Commercial support is available from Julia Computing."
  },
  {
    "objectID": "intro.html#how-is-julia-different",
    "href": "intro.html#how-is-julia-different",
    "title": "1  Introduction",
    "section": "1.2 How is Julia different?",
    "text": "1.2 How is Julia different?\n\n1.2.1 The Julia Manifesto\nWhen asked why they created Julia, the four founders Jeff Bezanson, Stefan Karpinski, Viral B. Shah, and Alan Edelman answered:\n\nIn short, because we are greedy.\nWe are power Matlab users. Some of us are Lisp hackers. Some are Pythonistas, others Rubyists, still others Perl hackers. There are those of us who used Mathematica before we could grow facial hair. There are those who still can’t grow facial hair. We’ve generated more R plots than any sane person should. C is our desert island programming language.\nWe love all of these languages; they are wonderful and powerful. For the work we do — scientific computing, machine learning, data mining, large-scale linear algebra, distributed and parallel computing — each one is perfect for some aspects of the work and terrible for others. Each one is a trade-off.\nWe are greedy: we want more.\nWe want a language that’s open source, with a liberal license. We want the speed of C with the dynamism of Ruby. We want a language that’s homoiconic, with true macros like Lisp, but with obvious, familiar mathematical notation like Matlab. We want something as usable for general programming as Python, as easy for statistics as R, as natural for string processing as Perl, as powerful for linear algebra as Matlab, as good at gluing programs together as the shell. Something that is dirt simple to learn, yet keeps the most serious hackers happy. We want it interactive and we want it compiled.\n(Did we mention it should be as fast as C?)\nWhile we’re being demanding, we want something that provides the distributed power of Hadoop — without the kilobytes of boilerplate Java and XML; without being forced to sift through gigabytes of log files on hundreds of machines to find our bugs. We want the power without the layers of impenetrable complexity. We want to write simple scalar loops that compile down to tight machine code using just the registers on a single CPU. We want to write A*B and launch a thousand computations on a thousand machines, calculating a vast matrix product together.\nWe never want to mention types when we don’t feel like it. But when we need polymorphic functions, we want to use generic programming to write an algorithm just once and apply it to an infinite lattice of types; we want to use multiple dispatch to efficiently pick the best method for all of a function’s arguments, from dozens of method definitions, providing common functionality across drastically different types. Despite all this power, we want the language to be simple and clean.\nAll this doesn’t seem like too much to ask for, does it?\nEven though we recognize that we are inexcusably greedy, we still want to have it all. About two and a half years ago, we set out to create the language of our greed. It’s not complete, but it’s time for an initial[1] release — the language we’ve created is called Julia. It already delivers on 90% of our ungracious demands, and now it needs the ungracious demands of others to shape it further. So, if you are also a greedy, unreasonable, demanding programmer, we want you to give it a try.\n\nOk, that’s a lot of geekery in there, so what does that mean for you, the user of a scientific language?"
  },
  {
    "objectID": "juliaFeatures.html#just-in-time-compilation-and-the-two-language-problem",
    "href": "juliaFeatures.html#just-in-time-compilation-and-the-two-language-problem",
    "title": "2  Julia Features for Scientic Computing",
    "section": "2.1 Just-In-Time Compilation and the Two Language Problem",
    "text": "2.1 Just-In-Time Compilation and the Two Language Problem\nMany scientific models are developed in prototyping languages like Python (or Matlab), since they are interactive, i.e., they run in an “read-eval-print-loop” (REPL), which offers immediate feedback and results, encouraging experimentation and “playing” with the code. This is a key feature for many scientists, as opposed to software developers, since it allows for quick development of a working model.\nThe problem with these interactive languages is, that they tend to be interpreted, and this much slower than compiled languages. We will see later that, e.g., Python can be up to 3 orders of magnitude slower than a compiled language, which also has huge implications on energy efficiency of scientific computing, as a contributor to climate change (Pereira et al. 2017, 2021).\n\nPereira, Rui, Marco Couto, Francisco Ribeiro, Rui Rua, Jácome Cunha, João Paulo Fernandes, and João Saraiva. 2017. “Energy Efficiency Across Programming Languages: How Do Energy, Time, and Memory Relate?” In Proceedings of the 10th ACM SIGPLAN International Conference on Software Language Engineering, 256–67. SLE 2017. New York, NY, USA: Association for Computing Machinery. https://doi.org/10.1145/3136014.3136031.\n\n———. 2021. “Ranking Programming Languages by Energy Efficiency.” Science of Computer Programming 205 (May): 102609. https://doi.org/10.1016/j.scico.2021.102609.\nSo with any interpreted language scientific computing will arrive at the point where the performance of the developed code is no longer sufficient. Usually the next step in these cases is either\n\nabandonment of the model.\nre-implementation of the model in a compiled language like Fortran or C.\n\nThis is what is called the “Two Language Problem”.\nThe two-language-problem is particularly concerning for scientific computing, since most engineers and natural scientists are not computer-scientists or software developers, or coders. Many of us do not readily speak a compiled language which would require writing code on a much lower abstraction level than most of us are comfortable with6.6 I do know how to write Fortran, but it is a much more daunting prospect than doing the same thing in Julia (or Matlab or Python).\nJulia can overcome this problem by virtue of being “just-in-time” compiled. This means that on the surface it looks like an interpreted language, while, behind the scenes and completely transparent to the user, the code is compiled to machine code and then executed. The Julia developers coined the phrase:\n\n“Feels like Python, runs like C.”\n\nWith only little effort, we can write Julia code that runs at the same speed as optimised Fortran or C code7.7 In fact, Julia is the only dynamically typed language that has managed to join the exclusive Petaflop Club of peak performance of greater than one petaflops (1015 floating point operations per second), scaling to over 1 million threads."
  },
  {
    "objectID": "juliaBasics.html",
    "href": "juliaBasics.html",
    "title": "Julia Basics",
    "section": "",
    "text": "I don’t want to give a full introduction to Julia. There are other, better resources for that (see Appendix A)."
  },
  {
    "objectID": "installingJulia.html#installation-on-windows",
    "href": "installingJulia.html#installation-on-windows",
    "title": "3  Installing Julia",
    "section": "3.1 Installation on Windows",
    "text": "3.1 Installation on Windows\nFor Windows users, Julia is available from the Microsoft App Store. Simply open the app store and search for Julia1 and install it. This will use the Julia Updater to install Julia in the user’s home folder, so no administrator rights are needed2.1 Look for the distinctive three coloured dot icon.2 This makes this method of installation ideal for university computers."
  },
  {
    "objectID": "installingJulia.html#installation-on-macos-and-linux",
    "href": "installingJulia.html#installation-on-macos-and-linux",
    "title": "3  Installing Julia",
    "section": "3.2 Installation on MacOS and Linux",
    "text": "3.2 Installation on MacOS and Linux\nGo to the JuliaUp github page and follow the instructions there.\nIf you do not believe in reading the documentation of software you are going to install, this should do it3:3 No guarantees! If your computer breaks, don’t blame me.\ncurl -fsSL https://install.julialang.org | sh"
  },
  {
    "objectID": "installingJulia.html#starting-the-repl",
    "href": "installingJulia.html#starting-the-repl",
    "title": "3  Installing Julia",
    "section": "3.3 Starting the REPL",
    "text": "3.3 Starting the REPL\nIn Windows, start the REPL from the Start menu, in Linux, open a terminal and type:\njulia"
  },
  {
    "objectID": "installingJulia.html#installing-packages",
    "href": "installingJulia.html#installing-packages",
    "title": "3  Installing Julia",
    "section": "3.4 Installing packages",
    "text": "3.4 Installing packages\nJulia has it’s own package manager which makes it easy to install packages and resolve dependencies.\nThe easiest way to install these is interactively, using the Julia REPL:\nIn the REPL, press the ] key, which will bring up the package manager prompt4. Then type the install command:4 Press the Left Arrow key to return to the Julia prompt.\n   _       _ _(_)_     |  Documentation: https://docs.julialang.org\n  (_)     | (_) (_)    |\n   _ _   _| |_  __ _   |  Type \"?\" for help, \"]?\" for Pkg help.\n  | | | | | | |/ _` |  |\n  | | |_| | | | (_| |  |  Version 1.9.0-beta4 (2023-02-07)\n _/ |\\__'_|_|_|\\__'_|  |  Official https://julialang.org/ release\n|__/                   |\n\n(@v1.9) pkg> add DifferentialEquations\nThis will install the package DifferentialEquations in the default environment (@v1.9)5. You can also create project environments to make your research fully reproducible by ensuring that the packages used, e.g., in a publication are the same as the ones used later, when you revisit the problem.5 At the time of writing that is version 1.9."
  },
  {
    "objectID": "ODEsolver.html#example-4-element-windkessel-model",
    "href": "ODEsolver.html#example-4-element-windkessel-model",
    "title": "7  Solving ODEs and ODE systems",
    "section": "7.1 Example: 4-Element Windkessel Model",
    "text": "7.1 Example: 4-Element Windkessel Model\n Download Jupyter Notebook \nThe windkessel model is a common model for the pressure response of the vascular system (blood circulation) to a periodic, pulsing flow waveform (Westerhof et al. 2019).\n\nWesterhof, Nicolaas, Nikolaos Stergiopulos, Mark I. M. Noble, and Berend E. Westerhof. 2019. Snapshots of Hemodynamics: An Aid for Clinical Research and Graduate Education. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-319-91932-4.\n\nStergiopulos, Nikos, Berend E. Westerhof, and Nico Westerhof. 1999. “Total Arterial Inertance as the Fourth Element of the Windkessel Model.” American Journal of Physiology-Heart and Circulatory Physiology 276 (1): H81–88. https://doi.org/10.1152/ajpheart.1999.276.1.H81.\nHere we are going to work with the 4-Element windkessel model (Stergiopulos, Westerhof, and Westerhof 1999), comprising a flow source (time dependent flow rate), two resistors for characteristic Resistance of the near vessel (aorta), \\(R_{c}\\), and systemic (peripheral) resistance, \\(R_{p}\\), a compliance (capacitance) \\(C\\), representing the blood storage capacity of the peripheral vessels, and an inductance \\(L_p\\), representing the inertia in the proximal, large vessel, e.g., the aorta.\nThe pressures in this circuit - \\(p_{1}\\) before, and \\(p_{2}\\) after the proximal L-R element - are described by the system of ODEs:\n\\[\n\\frac{d p_{1}}{d t}  =  - \\frac{R_{c}}{L_{p}} p_{1} + \\left( \\frac{R_{c}}{L_{p}} - \\frac{1}{R_{p} C} \\right) p_{2}\n+ R_{c} \\frac{d I(t)}{d t} + \\frac{I(t)}{C}\n\\tag{7.1}\\]\n\\[\n\\frac{d p_{2}}{d t}  =  - \\frac{1}{R_{p} C} p_{2} + \\frac{I(t)}{C}\n\\tag{7.2}\\]\n\n\n\n\nFigure 7.1: 4-Element Windkessel Model\n\n\nIn order to implement this model, we need to load the required modules. We use DifferentialEquations, Plots, and ForwardDiff for the time-derivative \\(\\frac{\\partial I}{\\partial t}\\):\n\nusing DifferentialEquations, ForwardDiff, Plots\n\nThe input waveform is a generic half-period of a sine-wave with a systolic (ejection) time of \\(t_{syst} = 0.4 T\\), with \\(T=1\\ \\mathrm{s}\\) period-time (60 beats per minute). The dicrotic notch is modelled by running the sine into the negative for \\(t_{dicr} = 0.03\\ \\mathrm{s}\\):\n\\[\\begin{equation}\n    I =\n    \\begin{cases}\n        I_{min} + (I_{max} - I_{min})  \\sin \\left(\\frac{\\pi}{t_{syst}} t \\right) & \\text{if } t < (t_{syst} + t_{dicr})\\\\\n        I_{min} & \\text{else}\n    \\end{cases}\n\\end{equation}\\]\nIn Julia, this function is implemented as2:2 Note that we use type specifications to define the parameters. Julia does suffer in performance, when untyped global variables are used, since these break type stability in the multiple dispatch. Making these parameter constant fixes their type. We should really be using these parameters in the function definition, or use a lambda function. But a lambda function is slower than typed variables.\n\n# max and min volume flow in ml/s\nmax_i::Float64 = 425\nmin_i::Float64 = 0.0\n\n# period time\nT::Float64 = 1.0\n\n# Syst. Time in s\nsystTime::Float64 = 2 / 5 * T\n\n# Dicrotic notch time in s\ndicrTime::Float64 = 0.03\n\nfunction I(t)\n    # implicit conditional using boolean multiplicator\n    # sine waveform\n    t = t - T * (t ÷ T)\n\n    return ((max_i - min_i) * sin(pi / systTime * (t))\n            * (t < (systTime + dicrTime) )\n            + min_i)\nend \n\nWe can quickly plot this function in Figure 7.2.\n\nplotTime = LinRange(0,1,100)\n\nplot(plotTime, I.(plotTime),\n     xlabel = \"t [s]\", ylabel = \"I [ml s<sup>-1</sup>]\", label = \"Outflow\") \n\n\n    \n    \nFigure 7.2: Generic waveform, representing ejection of blood from left ventricle in the aorta, including dicrotic notch (backflow at valve closure).\n\n\n\nThe definition of the ODEs Equation 7.1 and Equation 7.2 is done as a function with parameters dP and P, for \\(\\frac{d p_{1,2}}{d t}\\), and \\(p_{1,2}\\), respectively33 P is a vector of values, actually, as is dP.\n\nfunction wk4(dP, P, params, t)\n\n    Rc, Rp, C, Lp = params\n\n    dP[1] = (\n        -Rc / Lp * P[1]\n        + (Rc / Lp - 1 / Rp / C) * P[2]\n        + Rc * ForwardDiff.derivative(I, t)\n        + I(t) / C\n        )\n\n    dP[2] = -1 / Rp / C * P[2] + I(t) / C\n\n    return dP[1], dP[2]\n\nend\n\nWe define the parameters, initial conditions, and time span for the integration:\n\nRc = 0.03\nRp = 1.0\nC  = 2.0\nLp = 0.02\n\ntspan = (0, 10)\n\nparams = [Rc, Rp, C, Lp]\n\nP0 = zeros(2)\n\n2-element Vector{Float64}:\n 0.0\n 0.0\n\n\nAnd define the ODE problem and solve it4. We will time the run using the @time macro:4 We use the Dormand-Prince solver DP5 here, because that is the same algorithm that Matlab’s ode45 uses. DifferentialEquations.jl has a multitude of other solvers that may perform better. Play around with these.\n\nprob = ODEProblem(wk4, P0, tspan, params)\n\n@time sol = solve(prob, DP5(), reltol=1e-9);\n\n  0.256176 seconds (166.86 k allocations: 11.130 MiB, 99.37% compilation time: 100% of which was recompilation)\n\n\nLooking at this run time, we see that the run is slower than the Matlab run5. Looking at the details of the benchmark times, we see that most of that time has been used on compilation. So when we re-run the solver, it should take less time:5 See below. What happened here? Doesn’t everybody say how much faster Julia is than Matlab?\n\n@time sol = solve(prob, DP5(), reltol=1e-9);\n\n  0.001490 seconds (2.95 k allocations: 252.766 KiB)\n\n\nAnd indeed, the run time is now one order of magnitude faster than the Matlab times shown in Section 7.1.1.\nWe can plot the solution in Figure 7.3 using the special plot recipe for ODE solutions:\n\nplot(sol,\n     label = [\"p1\" \"p2\"],\n     xlabel = \"t [s]\",\n     ylabel = \"p [mm<sub>Hg</sub>]\",\n     tspan=(9,10))\n\n\n    \n    \nFigure 7.3: Solution of 4-element windkessel model using Julia’s DifferentialEquations.jl\n\n\n\n\n7.1.1 Comparison to Python and Matlab\nFor those coming from Python or Matlab, let’s have a look at how this problem can be solved in these two languages and compare to the Julia version.\nSwitch between the languages using the tabs below:\n\nPythonMATLAB\n\n\n Download Python Code \nimport scipy as sp\nfrom scipy import integrate\nfrom scipy.misc import derivative\n\nimport numpy as np\n\nimport time\n\ndef wk4(t, y, I, Rc, Rp, C, Lp, dt):\n\n    dp1dt = (\n        -Rc / Lp * y[0]\n        + (Rc / Lp - 1 / Rp / C) * y[1]\n        + Rc * derivative(I, t, dx=dt)\n        + I(t) / C\n    )\n\n    dp2dt = -1 / Rp / C * y[1] + I(t) / C\n\n    return [dp1dt, dp2dt]\n\ntime_start = 0\ntime_end = 10\n\nRc = 0.2\nRp = 1.0\nC = 1.0\nLp = 1e-2\n\ndt = 1e-6\n\ny0 = np.zeros(2)\n\n# Generic Input Waveform\n# max volume flow in ml/s\nmax_i = 425\n\n# min volume flow in m^3/s\nmin_i = 0.0\n\n# Period time in s\nT = 0.9\n\n# Syst. Time in s\nsystTime = 2 / 5 * T\n\n# Dicrotic notch time\ndicrTime = 0.03\n\ndef I(t):\n    # implicit conditional using boolean multiplicator\n    # sine waveform\n    I = (\n        (max_i - min_i) * np.sin(np.pi / systTime * (t % T))\n        *(t % T < (systTime + dicrTime)) + min_i\n    )\n\n    return I\n\ntic = time.perf_counter()\n\nsol = sp.integrate.solve_ivp(\n    lambda t, y: wk4(t, y, I, Rc, Rp, C, Lp, dt),\n    (time_start, time_end),\n    y0,\n    method=\"RK45\",\n    rtol=1e-9,\n    vectorized=True,) \n\ntoc = time.perf_counter()\n\nprint(f\"Time elapsed: {toc - tic:0.4f} seconds\")\nRuntime for this code is (timed using time.perf.counter in Python):\nTime elapsed: 0.7872 seconds\n\n\n Download Matlab Code \ntspan = [0, 10];\n\nRc = 0.03;\nRp = 1.0;\nC = 2.0;\nLp = 1e-2;\n\nP0 = [0, 0];\n\noptions        = odeset('Reltol',1e-9);\n\ntic\n[t, P] = ode45(@(t,P) wk4(t,P,Rc,Rp,C,Lp), tspan, P0, options);\ntoc\n\n\n\nfunction dP = wk4(t,P,Rc,Rp,C,Lp)\n\ndP    = zeros(2,1);\n\ndP(1) = -Rc / Lp * P(1) ...\n    + (Rc / Lp - 1 / Rp / C) * P(2) ...\n    + Rc * didt(t) + i(t) / C;\n\ndP(2) = -1 / Rp / C * P(2) + i(t) / C;\n\nend\n\nfunction i = i(t)\n\nmax_i = 425;\nmin_i = 0.0;\n\nT = 0.9;\n\nsystTime = 2 / 5 * T;\n\ndicrTime = 0.03;\n\ni = ((max_i - min_i) * sin(pi / systTime * (mod(t,T))) ...\n    *(mod(t,T) < (systTime + dicrTime)) ...\n    + min_i);\n\nend\n\nfunction didt = didt(t)\ndt = 1e-3;\ndidt = (i(t+dt) - i(t-dt)) / (2 * dt);\nend\nRuntime for this code is (timed using tic toc in Matlab)6, which is a bit more than an order of magnitude slower than Julia:6 Same code in Octave, the free open-source version of Matlab runs in 3 seconds. Current versions of Matlab have improved runtime by partial just-in-time compilation. Note that the first run in Matlab is also slightly longer with 0.035 seconds, which is most likely due to Matlab optimising the solver to the problem.\nElapsed time is 0.018172 seconds.\n\n\n\nSo in this case, Julia is one order of magitude faster than Matlab and around 500x faster than Python7 solving ODEs.7 I have tried using PyPy and Cython in other cases and found that they speed up Python considerably. Unfortunately this was not the case when using SciPy and Numpy, which made the compiled Python version one order of magnitude slower than interpreted. There seems to be a problem with C-calls from PyPy.\nPersonally, I find the Matlab code and, in particular, the Julia code easier to read."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Pereira, Rui, Marco Couto, Francisco Ribeiro, Rui Rua, Jácome Cunha,\nJoão Paulo Fernandes, and João Saraiva. 2017. “Energy Efficiency\nAcross Programming Languages: How Do Energy, Time, and Memory\nRelate?” In Proceedings of the 10th ACM SIGPLAN\nInternational Conference on Software Language\nEngineering, 256–67. SLE 2017. New York,\nNY, USA: Association for Computing Machinery. https://doi.org/10.1145/3136014.3136031.\n\n\n———. 2021. “Ranking Programming Languages by Energy\nEfficiency.” Science of Computer Programming 205 (May):\n102609. https://doi.org/10.1016/j.scico.2021.102609.\n\n\nStergiopulos, Nikos, Berend E. Westerhof, and Nico Westerhof. 1999.\n“Total Arterial Inertance as the Fourth Element of the Windkessel\nModel.” American Journal of Physiology-Heart and Circulatory\nPhysiology 276 (1): H81–88. https://doi.org/10.1152/ajpheart.1999.276.1.H81.\n\n\nWesterhof, Nicolaas, Nikolaos Stergiopulos, Mark I. M. Noble, and Berend\nE. Westerhof. 2019. Snapshots of Hemodynamics: An\nAid for Clinical Research and Graduate\nEducation. Cham: Springer International\nPublishing. https://doi.org/10.1007/978-3-319-91932-4."
  },
  {
    "objectID": "tricks.html#acknowledgment",
    "href": "tricks.html#acknowledgment",
    "title": "6  Some Clever Tricks in Julia",
    "section": "6.1 Acknowledgment",
    "text": "6.1 Acknowledgment\nSome of these tricks are taken from Julia Notes."
  }
]